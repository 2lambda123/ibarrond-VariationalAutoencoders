{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(object):\n",
    "    def __init__(self, name,\n",
    "                 n_inputs=784,\n",
    "                 n_neurons_encoder = [2048, 256],\n",
    "                 n_latent=2,\n",
    "                 n_neurons_decoder = [256, 2048],\n",
    "                 batch_size = 128,\n",
    "                 activation = tf.nn.tanh):\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "        # ATTRIBUTES\n",
    "        self.N = n_inputs\n",
    "        self.n_encoder = n_neurons_encoder\n",
    "        self.n_decoder = n_neurons_decoder\n",
    "        self.n_latent = n_latent\n",
    "        self.length_encoder = len(n_neurons_encoder)\n",
    "        self.length_decoder = len(n_neurons_decoder)\n",
    "        self.layers = self.length_encoder + self.length_decoder + 1 \n",
    "        self.activ = activation\n",
    "        \n",
    "        ## DATA PLACEHOLDERS (BATCHES)\n",
    "        with tf.name_scope('input'):\n",
    "            self.X = tf.placeholder(tf.float32, shape=[None, self.N], name='X')\n",
    "            \n",
    "        with tf.name_scope('input_reshape'):\n",
    "            image_shaped_input = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            tf.summary.image('input', image_shaped_input, 10)\n",
    "        \n",
    "        # INITIALIZE WEIGHTS & BIASES\n",
    "        self.W_enc, self.W_z_mu, self.W_z_log_sigma, self.W_dec = self.initialize_W()\n",
    "        self.b_enc, self.b_z_mu, self.b_z_log_sigma, self.b_dec = self.initialize_b()\n",
    "            \n",
    "        ## COMPUTATIONAL GRAPH\n",
    "        self.Y, self.z_mu, self.z_log_sigma, _ = self.feedforward()\n",
    "        self.loss, self.kl, self.ell = self.get_nelbo()\n",
    "\n",
    "        ## Initialize the session\n",
    "        self.session = tf.InteractiveSession()\n",
    "    \n",
    "        print(\"VAE \"+self.name)\n",
    "        self.print_network_size()\n",
    "        \n",
    "        \n",
    "    def print_network_size(self):\n",
    "        \"\"\"Print the sizes of biases and weights\"\"\"\n",
    "        print(\" --> Encoder\")        \n",
    "        for w, b in zip(self.W_enc, self.b_enc):\n",
    "            print(w.get_shape(), b.get_shape())\n",
    "            \n",
    "        print(\" --> Latent Space\")   \n",
    "        print(self.W_z_mu.get_shape(), self.b_z_mu.get_shape())\n",
    "        print(self.W_z_log_sigma.get_shape(), self.b_z_log_sigma.get_shape())\n",
    "        \n",
    "        print(\" --> Decoder\")   \n",
    "        for w, b in zip(self.W_dec, self.b_dec):\n",
    "            print(w.get_shape(), b.get_shape())\n",
    "\n",
    "    ## ---------------------------------------------------------------------            \n",
    "    ## --------------- TF WEIGHTS & BIASES INITIALIZATION ------------------\n",
    "    ## ---------------------------------------------------------------------\n",
    "    \n",
    "    def initialize_W(self):\n",
    "        \"\"\"\n",
    "        Define all the weights for the network.\n",
    "        We initialize them to standard normal iid using Xavier Initializer\n",
    "        \"\"\"\n",
    "        \n",
    "        W_encoder = []\n",
    "        W_latent_mu = []\n",
    "        W_latent_log_sigma = []\n",
    "        W_decoder = []\n",
    "        \n",
    "        with tf.name_scope(\"Encoder_layer_weights\"):\n",
    "            W_encoder.append(w_xavier(shape=[self.N, self.n_encoder[0]]))\n",
    "            for i in range(1, self.length_encoder):\n",
    "                W_encoder.append(w_xavier(shape=[self.n_encoder[i-1], self.n_encoder[i]]))\n",
    "        \n",
    "        with tf.name_scope(\"Latent_layer_weights\"):\n",
    "            W_latent_mu = w_xavier(shape =[self.n_encoder[-1], self.n_latent]) \n",
    "            W_latent_log_sigma = w_xavier(shape =[self.n_encoder[-1], self.n_latent])      \n",
    "            \n",
    "        with tf.name_scope(\"Decoder_layer_weights\"):\n",
    "            W_decoder.append(w_xavier(shape=[self.n_latent, self.n_decoder[0]]))\n",
    "            for i in range(1, self.length_decoder):\n",
    "                W_decoder.append(w_xavier(shape=[self.n_decoder[i-1], self.n_decoder[i]]))\n",
    "            W_decoder.append(w_xavier(shape=[self.n_decoder[-1], self.N]))\n",
    "        \n",
    "        return W_encoder, W_latent_mu, W_latent_log_sigma, W_decoder\n",
    "\n",
    "    \n",
    "    def initialize_b(self):\n",
    "        \"\"\"\n",
    "        Define all the biases for the network.\n",
    "        We initialize them to standard normal iid using Xavier Initializer\n",
    "        \"\"\"\n",
    "        \n",
    "        b_encoder = []\n",
    "        b_latent_mu = []\n",
    "        b_latent_log_sigma = []\n",
    "        b_decoder = []\n",
    "        \n",
    "        with tf.name_scope(\"Encoder_layer_biases\"):\n",
    "            b_encoder.append(b_xavier(shape=[self.n_encoder[0]]))\n",
    "            for i in range(1, self.length_encoder):\n",
    "                b_encoder.append(b_xavier(shape=[self.n_encoder[i]]))\n",
    "        \n",
    "        with tf.name_scope(\"Latent_layer_biases\"):\n",
    "            b_latent_mu = b_xavier(shape =[self.n_latent]) \n",
    "            b_latent_log_sigma = b_xavier(shape =[self.n_latent])      \n",
    "            \n",
    "        with tf.name_scope(\"Decoder_layer_biases\"):\n",
    "            b_decoder.append(b_xavier(shape=[self.n_decoder[0]]))\n",
    "            for i in range(1, self.length_decoder):\n",
    "                b_decoder.append(b_xavier(shape=[self.n_decoder[i]]))\n",
    "            b_decoder.append(b_xavier(shape=[self.N]))\n",
    "            \n",
    "        return b_encoder, b_latent_mu, b_latent_log_sigma, b_decoder\n",
    "\n",
    "    \n",
    "    ## ---------------------------------------------------------------------            \n",
    "    ## ----------------- SAMPLING FROM THE LATENT SPACE --------------------\n",
    "    ## ---------------------------------------------------------------------\n",
    "    \n",
    "    def get_samples(self, d_in, d_out):\n",
    "        \"\"\"\n",
    "        Sample from noise distribution p(eps) ~ N(0, 1)\n",
    "        a matrix of samples of dimension [d_in, d_out].\n",
    "        \"\"\"\n",
    "        return tf.random_normal(shape=[d_in, d_out])\n",
    "\n",
    "    def sample_from_Z(self, z_mu, z_log_o):\n",
    "        \"\"\"\n",
    "        Samples from the posterior of the variational latent space.\n",
    "        We draw samples using the reparameterization trick.\n",
    "        \"\"\"\n",
    "        return z_mu + tf.exp(z_log_o) * self.get_samples(tf.shape(self.X)[0], self.n_latent)\n",
    "    \n",
    "        \n",
    "        \n",
    "    ## ---------------------------------------------------------------------            \n",
    "    ## --------------------------- FEEDFORWARD -----------------------------\n",
    "    ## ---------------------------------------------------------------------\n",
    "    def encoder(self, net):\n",
    "        '''ENCODER: transform the input image into the latent space'''\n",
    "        for i in range(self.length_encoder):\n",
    "            net = self.activ(tf.matmul(net, self.W_enc[i]) + self.b_enc[i])\n",
    "            \n",
    "        z_mu = tf.matmul(net, self.W_z_mu) + self.b_z_mu\n",
    "        z_log_sigma = 0.5 * (tf.matmul(net, self.W_z_log_sigma) + self.b_z_log_sigma)\n",
    "        \n",
    "        return z_mu, z_log_sigma\n",
    "        \n",
    "        \n",
    "    def decoder(self, z):\n",
    "        '''DECODER: transform a Latent Space representation into an image'''\n",
    "        net = self.activ(tf.matmul(z, self.W_dec[0]) + self.b_dec[0])\n",
    "        for i in range(1, self.length_decoder):\n",
    "            net = self.activ(tf.matmul(net, self.W_dec[i]) + self.b_dec[i])\n",
    "        \n",
    "        return tf.nn.sigmoid(tf.matmul(net, self.W_dec[-1]) + self.b_dec[-1])        \n",
    "                \n",
    "    \n",
    "    def feedforward(self):\n",
    "        \"\"\"\n",
    "        Feedforward pass excluding last layer's transfer function.\n",
    "        intermediate : index of intermediate layer for output generation\n",
    "        \"\"\"\n",
    "        net = self.X\n",
    "\n",
    "        # ENCODER\n",
    "        z_mu, z_log_sigma = self.encoder(net)\n",
    "\n",
    "        # LATENT: Sample from posterior\n",
    "        z = self.sample_from_Z(z_mu, z_log_sigma)\n",
    "\n",
    "        # DECODER\n",
    "        Y = self.decoder(z)        \n",
    "                \n",
    "        return Y, z_mu, z_log_sigma, z\n",
    "    \n",
    "    \n",
    "    ## ---------------------------------------------------------------------            \n",
    "    ## ------------------- LOSS: EXPECTED LOWER BOUND ----------------------\n",
    "    ## ---------------------------------------------------------------------    \n",
    "    \n",
    "    def get_ell(self):\n",
    "        \"\"\"\n",
    "        Returns the expected log-likelihood of the lower bound.\n",
    "        For this we use a bernouilli LL.\n",
    "        \"\"\"\n",
    "        target = self.X\n",
    "        output = self.Y\n",
    "        # p(x|z)        \n",
    "        return - tf.reduce_sum((  target  ) * tf.log(output + 1e-10) +\n",
    "                               (1 - target) * tf.log(1 - output + 1e-10), 1)\n",
    "\n",
    "    \n",
    "    def get_kl(self):\n",
    "        \"\"\"\n",
    "        d_kl(q(z|x)||p(z)) returns the KL-divergence between the prior p and the variational posterior q.\n",
    "        :return: KL divergence between q and p\n",
    "        \"\"\"   \n",
    "        # Formula: 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "        return - 0.5 * tf.reduce_sum( 1.0 + 2.0 * self.z_log_sigma - tf.square(self.z_mu) -\n",
    "                                   tf.exp(2.0 * self.z_log_sigma), 1)\n",
    "        \n",
    "        \n",
    "    def get_nelbo(self):\n",
    "        \"\"\" Returns the negative ELBOW, which allows us to minimize instead of maximize. \"\"\"\n",
    "        kl = tf.reduce_mean(self.get_kl())\n",
    "        ell = tf.reduce_mean(self.get_ell())\n",
    "        nelbo = kl + ell\n",
    "        return nelbo, kl, ell\n",
    "    \n",
    "    \n",
    "    ## ---------------------------------------------------------------------            \n",
    "    ## --------------------------- LEARNING --------------------------------\n",
    "    ## ---------------------------------------------------------------------  \n",
    "    \n",
    "    def learn(self, learning_rate=0.001, batch_size=128,\n",
    "                    epochs=100, display_step=1):\n",
    "        \"\"\" Our learning procedure \"\"\"\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "        ## Set all_variables to contain the complete set of TF variables to optimize\n",
    "        all_variables = tf.trainable_variables()\n",
    "\n",
    "        ## Define the optimizer\n",
    "        train_step = optimizer.minimize(self.loss, var_list=all_variables)\n",
    "\n",
    "        tf.summary.scalar('negative_elbo', self.loss)\n",
    "        #tf.summary.scalar('kl_div', self.kl)\n",
    "        #tf.summary.scalar('ell', self.ell)\n",
    "        \n",
    "        merged = tf.summary.merge_all()\n",
    "        \n",
    "        train_writer = tf.summary.FileWriter('logs/train', self.session.graph)\n",
    "        test_writer = tf.summary.FileWriter('logs/test')        \n",
    "        \n",
    "        ## Initialize all variables\n",
    "        self.session.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Initial model print\n",
    "        print(\"*MODEL [\", self.name,\"] {l_r: %.4f; n_iter: %d; batch: %d}\"%\\\n",
    "              (learning_rate, epochs, batch_size))\n",
    "        print (\" -> START Training!\")\n",
    "        \n",
    "        t = time.time()\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            train_cost = 0.\n",
    "            batch_ell = 0.\n",
    "            batch_kl = 0.\n",
    "            for batch_i in range(total_batch):\n",
    "                batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "\n",
    "                _, loss, ell, kl, summary = self.session.run(\n",
    "                    [train_step, self.loss, self.ell, self.kl, merged],\n",
    "                                    feed_dict={self.X: batch_xs})\n",
    "                \n",
    "                train_writer.add_summary(summary, epoch * total_batch + batch_i)\n",
    "                train_cost += loss / total_batch\n",
    "                batch_ell += ell / total_batch\n",
    "                batch_kl += kl / total_batch\n",
    "                \n",
    "            print(\"   [%.1f] Epoch: %02d | NELBO: %.6f | ELL: %.6f | KL: %.6f\"%(\n",
    "                time.time()-t,epoch, train_cost, batch_ell, batch_kl ))\n",
    "        \n",
    "        print (\" -> Training FINISHED in %.1f seconds.\"%(time.time()-t))\n",
    "        self.serialize('FOLDS/')\n",
    "        train_writer.close()\n",
    "        test_writer.close()\n",
    "        \n",
    "    def benchmark(self, validation=False, batch_size = 128):\n",
    "        # TEST LOG LIKELIHOOD\n",
    "        if validation:\n",
    "            benchmark_data = mnist.validation\n",
    "            title = 'Validation LogLikelihood:'\n",
    "        else:\n",
    "            benchmark_data = mnist.test\n",
    "            title = 'Test LogLikelihood:'\n",
    "        \n",
    "        total_batch = benchmark_data.num_examples // batch_size\n",
    "        ell = 0\n",
    "        for batch_i in range(total_batch):\n",
    "            batch_xs, _ = benchmark_data.next_batch(batch_size)\n",
    "            c = self.session.run(self.ell,\n",
    "                   feed_dict={self.X: batch_xs, self.Y: batch_xs})\n",
    "            ell+= c/total_batch\n",
    "        print(\"Model \", self.name, \". \", title, ell)\n",
    "        \n",
    "        # RECONSTRUCTION VISUALIZATION\n",
    "        f = plot_recon()\n",
    "        f.savefig(self.name+'_recon.png' % t_i)\n",
    "        \n",
    "        # LATENT SPACE VISUALIZATION\n",
    "        f = plot_recon()\n",
    "        f.savefig(self.name+'_recon.png' % t_i)\n",
    "        \n",
    "        return ell\n",
    "        \n",
    "    def serialize(self, path):\n",
    "        '''Save the model in a file'''\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(self.session, path+self.name)\n",
    "        print(\"Model saved in file: %s\" % path+self.name)\n",
    "        \n",
    "        \n",
    "    def restore(self, path):\n",
    "        '''Restore the saved model'''\n",
    "        \n",
    "        saver = tf.train.Saver()   \n",
    "        sess = tf.InteractiveSession()\n",
    "        saver.restore(sess, save_path=path)\n",
    "        self.session = sess\n",
    "        print(\"Model restored from file: %s\" % path)\n",
    "    \n",
    "    def encode(self, input_vector):\n",
    "        '''Encode the input into the Latent Space'''\n",
    "        \n",
    "        _, _, _, z = self.session.run(self.feedforward,\n",
    "                                feed_dict={self.X: input_vector})\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        '''Decode from the latent space into the out'''\n",
    "        \n",
    "        _, z_m, z_log_o = self.session.run(self.decode,\n",
    "                                feed_dict={self.X: input_vector})\n",
    "        return z_m, z_log_o\n",
    "    \n",
    "    \n",
    "    def plot_recon(self, n_examples=20):\n",
    "        '''Visualize Example Reconstrutions for the model'''\n",
    "        \n",
    "        xs = mnist.test.next_batch(n_examples)\n",
    "        recon = self.session.run(self.Y, feed_dict={self.X: xs})\n",
    "        fig, axs = plt.subplots(2, n_examples, figsize=(20, 4))\n",
    "        for i in range(n_examples):\n",
    "            axs[0][i].imshow(np.reshape(xs[i, :], (28, 28)), cmap='gray')\n",
    "            axs[1][i].imshow(np.reshape(recon[i, ...], (28, 28)), cmap='gray')\n",
    "            axs[0][i].axis('off')\n",
    "            axs[1][i].axis('off')\n",
    "        plt.show()\n",
    "        return fig\n",
    "    \n",
    "    \n",
    "    def plot_latent_recon(self, n_examples=20):        \n",
    "        '''Visualize Reconstructions from the latent space'''\n",
    "        \n",
    "        imgs = []\n",
    "        for img_i in np.linspace(-3, 3, n_examples):\n",
    "            for img_j in np.linspace(-3, 3, n_examples):\n",
    "                z = np.array([[img_i, img_j]], dtype=np.float32)\n",
    "                recon = self.session.run(self.Y, feed_dict={self.X: xs})\n",
    "                imgs.append(np.reshape(recon, (1, 28, 28, 1)))\n",
    "        imgs_cat = np.concatenate(imgs)\n",
    "        ax_manifold.imshow(montage_batch(imgs_cat))\n",
    "        fig_manifold.savefig('manifold_%08d.png' % t_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "def w_xavier(shape):\n",
    "    initial = tf.random_normal(shape, mean=0.0,\n",
    "                               stddev=tf.sqrt(3./sum(shape)))\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "# %%\n",
    "def b_xavier(shape):\n",
    "    initial = tf.random_normal(shape, mean=0.0,\n",
    "                               stddev=tf.sqrt(3./sum(shape)))\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE VA_1\n",
      " --> Encoder\n",
      "(784, 256) (256,)\n",
      "(256, 128) (128,)\n",
      " --> Latent Space\n",
      "(128, 2) (2,)\n",
      "(128, 2) (2,)\n",
      " --> Decoder\n",
      "(2, 128) (128,)\n",
      "(128, 256) (256,)\n",
      "(256, 784) (784,)\n"
     ]
    }
   ],
   "source": [
    "VA =  VariationalAutoencoder('VA_1',\n",
    "                 n_inputs=784,\n",
    "                 n_neurons_encoder = [256, 128],\n",
    "                 n_latent=2,\n",
    "                 n_neurons_decoder = [128, 256],\n",
    "                 batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*MODEL [ VA_1 ] {l_r: 0.0010; n_iter: 30; batch: 128}\n",
      " -> START Training!\n",
      "   [2.4] Epoch: 00 | NELBO: 194.150667 | ELL: -189.690730 | KL: 4.459936\n",
      "   [4.7] Epoch: 01 | NELBO: 167.858819 | ELL: -163.311105 | KL: 4.547714\n",
      "   [7.0] Epoch: 02 | NELBO: 161.223519 | ELL: -156.251087 | KL: 4.972433\n",
      "   [9.4] Epoch: 03 | NELBO: 157.020086 | ELL: -151.743727 | KL: 5.276359\n",
      "   [11.8] Epoch: 04 | NELBO: 153.735214 | ELL: -148.216445 | KL: 5.518769\n",
      "   [14.3] Epoch: 05 | NELBO: 151.586451 | ELL: -145.878668 | KL: 5.707784\n",
      "   [16.6] Epoch: 06 | NELBO: 149.691282 | ELL: -143.860337 | KL: 5.830945\n",
      "   [19.0] Epoch: 07 | NELBO: 148.412912 | ELL: -142.473502 | KL: 5.939410\n",
      "   [21.4] Epoch: 08 | NELBO: 147.353133 | ELL: -141.333383 | KL: 6.019750\n",
      "   [23.8] Epoch: 09 | NELBO: 146.704975 | ELL: -140.611974 | KL: 6.093001\n",
      "   [26.2] Epoch: 10 | NELBO: 145.803629 | ELL: -139.648479 | KL: 6.155149\n",
      "   [28.5] Epoch: 11 | NELBO: 145.221939 | ELL: -139.017170 | KL: 6.204769\n",
      "   [30.8] Epoch: 12 | NELBO: 144.585770 | ELL: -138.339295 | KL: 6.246475\n",
      "   [33.1] Epoch: 13 | NELBO: 144.062007 | ELL: -137.759468 | KL: 6.302539\n",
      "   [35.5] Epoch: 14 | NELBO: 143.773309 | ELL: -137.454729 | KL: 6.318581\n",
      "   [37.8] Epoch: 15 | NELBO: 143.308502 | ELL: -136.959904 | KL: 6.348598\n",
      "   [40.1] Epoch: 16 | NELBO: 142.867964 | ELL: -136.492643 | KL: 6.375321\n",
      "   [42.3] Epoch: 17 | NELBO: 142.577607 | ELL: -136.158985 | KL: 6.418621\n",
      "   [44.6] Epoch: 18 | NELBO: 142.117425 | ELL: -135.662544 | KL: 6.454881\n",
      "   [47.1] Epoch: 19 | NELBO: 141.898704 | ELL: -135.422962 | KL: 6.475742\n",
      "   [49.4] Epoch: 20 | NELBO: 141.627741 | ELL: -135.132367 | KL: 6.495374\n",
      "   [51.8] Epoch: 21 | NELBO: 141.341395 | ELL: -134.816498 | KL: 6.524897\n",
      "   [54.2] Epoch: 22 | NELBO: 141.123786 | ELL: -134.583025 | KL: 6.540761\n",
      "   [56.5] Epoch: 23 | NELBO: 140.900131 | ELL: -134.329727 | KL: 6.570403\n",
      "   [58.8] Epoch: 24 | NELBO: 140.518531 | ELL: -133.934705 | KL: 6.583825\n",
      "   [61.1] Epoch: 25 | NELBO: 140.491293 | ELL: -133.884965 | KL: 6.606328\n",
      "   [63.4] Epoch: 26 | NELBO: 140.154137 | ELL: -133.529196 | KL: 6.624941\n",
      "   [65.7] Epoch: 27 | NELBO: 140.057799 | ELL: -133.407455 | KL: 6.650344\n",
      "   [67.9] Epoch: 28 | NELBO: 139.779838 | ELL: -133.110281 | KL: 6.669558\n",
      "   [70.2] Epoch: 29 | NELBO: 139.709802 | ELL: -133.027725 | KL: 6.682076\n",
      " -> Training FINISHED in 70.2 seconds.\n",
      "Model saved in file: FOLDS/VA_1\n"
     ]
    }
   ],
   "source": [
    "VA.learn(epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2baba9c79e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VA.plot_enc_dec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "def weight_variable(shape):\n",
    "    initial = tf.random_normal(shape, mean=0.0, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "# %%\n",
    "def bias_variable(shape):\n",
    "    initial = tf.random_normal(shape, mean=0.0, stddev=0.01)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "def test_mnist():\n",
    "    \"\"\"Summary\n",
    "    Returns\n",
    "    -------\n",
    "    name : TYPE\n",
    "        Description\n",
    "    \"\"\"\n",
    "    # %%\n",
    "\n",
    "\n",
    "    # %%\n",
    "    # load MNIST as before\n",
    "    ae = VAE()\n",
    "\n",
    "    # %%\n",
    "    learning_rate = 0.001\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(ae['cost'])\n",
    "\n",
    "    # %%\n",
    "    # We create a session to use the graph\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # %%\n",
    "    # Fit all training data\n",
    "    t_i = 0\n",
    "    batch_size = 100\n",
    "    n_epochs = 50\n",
    "    n_examples = 20\n",
    "    test_xs, _ = mnist.test.next_batch(n_examples)\n",
    "    xs, ys = mnist.test.images, mnist.test.labels\n",
    "    fig_manifold, ax_manifold = plt.subplots(1, 1)\n",
    "    fig_reconstruction, axs_reconstruction = plt.subplots(2, n_examples, figsize=(10, 2))\n",
    "    fig_image_manifold, ax_image_manifold = plt.subplots(1, 1)\n",
    "    for epoch_i in range(n_epochs):\n",
    "        print('--- Epoch', epoch_i)\n",
    "        train_cost = 0\n",
    "        for batch_i in range(mnist.train.num_examples // batch_size):\n",
    "            batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "            train_cost += sess.run([ae['cost'], optimizer],\n",
    "                                   feed_dict={ae['x']: batch_xs})[0]\n",
    "            if batch_i == 1:\n",
    "                # %%\n",
    "                # Plot example reconstructions from latent layer\n",
    "                imgs = []\n",
    "                for img_i in np.linspace(-3, 3, n_examples):\n",
    "                    for img_j in np.linspace(-3, 3, n_examples):\n",
    "                        z = np.array([[img_i, img_j]], dtype=np.float32)\n",
    "                        recon = sess.run(ae['y'], feed_dict={ae['z']: z})\n",
    "                        imgs.append(np.reshape(recon, (1, 28, 28, 1)))\n",
    "                imgs_cat = np.concatenate(imgs)\n",
    "                ax_manifold.imshow(montage_batch(imgs_cat))\n",
    "                fig_manifold.savefig('manifold_%08d.png' % t_i)\n",
    "\n",
    "                # %%\n",
    "                # Plot example reconstructions\n",
    "                recon = sess.run(ae['y'], feed_dict={ae['x']: test_xs})\n",
    "                print(recon.shape)\n",
    "                for example_i in range(n_examples):\n",
    "                    axs_reconstruction[0][example_i].imshow(\n",
    "                        np.reshape(test_xs[example_i, :], (28, 28)),\n",
    "                        cmap='gray')\n",
    "                    axs_reconstruction[1][example_i].imshow(\n",
    "                        np.reshape(\n",
    "                            np.reshape(recon[example_i, ...], (784,)),\n",
    "                            (28, 28)),\n",
    "                        cmap='gray')\n",
    "                    axs_reconstruction[0][example_i].axis('off')\n",
    "                    axs_reconstruction[1][example_i].axis('off')\n",
    "                fig_reconstruction.savefig('reconstruction_%08d.png' % t_i)\n",
    "\n",
    "                # %%\n",
    "                # Plot manifold of latent layer\n",
    "                zs = sess.run(ae['z'], feed_dict={ae['x']: xs})\n",
    "                ax_image_manifold.clear()\n",
    "                ax_image_manifold.scatter(zs[:, 0], zs[:, 1],\n",
    "                    c=np.argmax(ys, 1), alpha=0.2)\n",
    "                ax_image_manifold.set_xlim([-6, 6])\n",
    "                ax_image_manifold.set_ylim([-6, 6])\n",
    "                ax_image_manifold.axis('off')\n",
    "                fig_image_manifold.savefig('image_manifold_%08d.png' % t_i)\n",
    "\n",
    "                t_i += 1\n",
    "\n",
    "\n",
    "        print('Train cost:', train_cost /\n",
    "              (mnist.train.num_examples // batch_size))\n",
    "\n",
    "        valid_cost = 0\n",
    "        for batch_i in range(mnist.validation.num_examples // batch_size):\n",
    "            batch_xs, _ = mnist.validation.next_batch(batch_size)\n",
    "            valid_cost += sess.run([ae['cost']],\n",
    "                                   feed_dict={ae['x']: batch_xs})[0]\n",
    "        print('Validation cost:', valid_cost /\n",
    "              (mnist.validation.num_examples // batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
