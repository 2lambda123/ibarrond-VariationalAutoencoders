{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ll(Y, output):\n",
    "    return np.sum(np.square(output - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    \"\"\"Leaky rectifier.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : Tensor\n",
    "        The tensor to apply the nonlinearity to.\n",
    "    leak : float, optional\n",
    "        Leakage parameter.\n",
    "    name : str, optional\n",
    "        Variable scope to use.\n",
    "    Returns\n",
    "    -------\n",
    "    x : Tensor\n",
    "        Output of the nonlinearity.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        f1 = 0.5 * (1 + leak)\n",
    "        f2 = 0.5 * (1 - leak)\n",
    "        return f1 * x + f2 * abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(3, 3, 1, 4)\n",
      "(4,)\n",
      "(3, 3, 4, 8)\n",
      "(8,)\n",
      "(3, 3, 8, 16)\n",
      "(16,)\n",
      "Shape z:  (?, 4, 4, 16)\n",
      "(3, 3, 8, 16)\n",
      "(8,)\n",
      "(3, 3, 4, 8)\n",
      "(4,)\n",
      "(3, 3, 1, 4)\n",
      "(1,)\n",
      "0 960254.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0669a6621563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;31m# %%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mtest_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-0669a6621563>\u001b[0m in \u001b[0;36mtest_mnist\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean_img\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mae\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mae\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cost'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mae\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python-projects/environments/tf-simd/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python-projects/environments/tf-simd/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python-projects/environments/tf-simd/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python-projects/environments/tf-simd/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python-projects/environments/tf-simd/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"Tutorial on how to create a convolutional autoencoder w/ Tensorflow.\n",
    "\n",
    "Parag K. Mital, Jan 2016\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "def autoencoder(input_shape=[None, 784],\n",
    "                n_filters=[1, 4, 8, 16],\n",
    "                filter_sizes=[3, 3, 3, 3],\n",
    "                corruption=False):\n",
    "    \"\"\"Build a deep denoising autoencoder w/ tied weights.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : list, optional\n",
    "        Description\n",
    "    n_filters : list, optional\n",
    "        Description\n",
    "    filter_sizes : list, optional\n",
    "        Description\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : Tensor\n",
    "        Input placeholder to the network\n",
    "    z : Tensor\n",
    "        Inner-most latent representation\n",
    "    y : Tensor\n",
    "        Output reconstruction of the input\n",
    "    cost : Tensor\n",
    "        Overall cost to use for training\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        Description\n",
    "    \"\"\"\n",
    "    # %%\n",
    "    # input to the network\n",
    "    x = tf.placeholder(\n",
    "        tf.float32, input_shape, name='x')\n",
    "    target = tf.placeholder(\n",
    "        tf.float32, input_shape, name='target')\n",
    "\n",
    "\n",
    "    # %%\n",
    "    # ensure 2-d is converted to square tensor.\n",
    "    if len(x.get_shape()) == 2:\n",
    "        x_dim = np.sqrt(x.get_shape().as_list()[1])\n",
    "        if x_dim != int(x_dim):\n",
    "            raise ValueError('Unsupported input dimensions')\n",
    "        x_dim = int(x_dim)\n",
    "        x_tensor = tf.reshape(\n",
    "            x, [-1, x_dim, x_dim, n_filters[0]])\n",
    "        y_tensor = tf.reshape(\n",
    "            target, [-1, x_dim, x_dim, n_filters[0]])\n",
    "    elif len(x.get_shape()) == 4:\n",
    "        x_tensor = x\n",
    "    else:\n",
    "        raise ValueError('Unsupported input dimensions')\n",
    "    current_input = x_tensor\n",
    "\n",
    "    # %%\n",
    "    # Optionally apply denoising autoencoder\n",
    "    #if corruption:\n",
    "    #    current_input = corrupt(current_input)\n",
    "\n",
    "    # %%\n",
    "    # Build the encoder\n",
    "    encoder = []\n",
    "    shapes = []\n",
    "    for layer_i, n_output in enumerate(n_filters[1:]):\n",
    "        n_input = current_input.get_shape().as_list()[3]\n",
    "        shapes.append(current_input.get_shape().as_list())\n",
    "        \n",
    "        W_means = tf.Variable(tf.zeros([\n",
    "                filter_sizes[layer_i],\n",
    "                filter_sizes[layer_i],\n",
    "                n_input, n_output]))\n",
    "        W_logdevs = tf.Variable(tf.zeros([\n",
    "                filter_sizes[layer_i],\n",
    "                filter_sizes[layer_i],\n",
    "                n_input, n_output]))\n",
    "\n",
    "        b_means = tf.Variable(tf.zeros([n_output]))\n",
    "        b_logdevs = tf.Variable(tf.zeros([n_output]))\n",
    "        \n",
    "        z_w = tf.random_normal(shape=W_means.shape)\n",
    "        z_b = tf.random_normal(shape=b_means.shape)\n",
    "        \n",
    "        W = tf.add(tf.multiply(z_w, tf.exp(W_logdevs / 2)), W_means)\n",
    "        b = tf.add(tf.multiply(z_b, tf.exp(b_logdevs / 2)), b_means)\n",
    "        \n",
    "        \n",
    "        encoder.append((W_means, W_logdevs))\n",
    "        output = lrelu(\n",
    "            tf.add(tf.nn.conv2d(\n",
    "                current_input, W, strides=[1, 2, 2, 1], padding='SAME'), b))\n",
    "        current_input = output\n",
    "        print(W.shape)\n",
    "        print(b.shape)\n",
    "\n",
    "    # %%\n",
    "    # store the latent representation\n",
    "    z = current_input\n",
    "    print('Shape z: ', z.shape)\n",
    "    encoder.reverse()\n",
    "    shapes.reverse()\n",
    "\n",
    "    # %%\n",
    "    # Build the decoder using the same weights\n",
    "    for layer_i, shape in enumerate(shapes):\n",
    "        W_means, W_logdevs = encoder[layer_i]\n",
    "        b_means = tf.Variable(tf.zeros([W_means.get_shape().as_list()[2]]))\n",
    "        b_logdevs = tf.Variable(tf.zeros([W_means.get_shape().as_list()[2]]))\n",
    "        \n",
    "        z_w = tf.random_normal(shape=W_means.shape)\n",
    "        z_b = tf.random_normal(shape=b_means.shape)\n",
    "        \n",
    "        W = tf.add(tf.multiply(z_w, tf.exp(W_logdevs / 2)), W_means)\n",
    "        b = tf.add(tf.multiply(z_b, tf.exp(b_logdevs / 2)), b_means)\n",
    "        output = tf.add(\n",
    "            tf.nn.conv2d_transpose(\n",
    "                current_input, W,\n",
    "                tf.stack([tf.shape(x)[0], shape[1], shape[2], shape[3]]),\n",
    "                strides=[1, 2, 2, 1], padding='SAME'), b)\n",
    "        \n",
    "        if layer_i < len(shapes) - 1:\n",
    "            output = lrelu(output)\n",
    "            \n",
    "        current_input = output\n",
    "        print(W.shape)\n",
    "        print(b.shape)\n",
    "        \n",
    "    # gaussian likelihood\n",
    "\n",
    "    output = tf.contrib.layers.flatten(output)\n",
    "    \n",
    "    \"\"\"\n",
    "    W_means = tf.Variable(tf.zeros([784,784]))\n",
    "    W_logdevs = tf.Variable(tf.zeros([784,784]))\n",
    "    b_means = tf.Variable(tf.zeros([784]))\n",
    "    b_logdevs = tf.Variable(tf.zeros([784]))\n",
    "    \n",
    "    z_w = tf.random_normal(shape=W_means.shape)\n",
    "    z_b = tf.random_normal(shape=b_means.shape)\n",
    "\n",
    "    W = tf.add(tf.multiply(z_w, tf.exp(W_logdevs / 2)), W_means)\n",
    "    b = tf.add(tf.multiply(z_b, tf.exp(b_logdevs / 2)), b_means)\n",
    "    \n",
    "    output = tf.matmul(output, W) + b\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # %%\n",
    "    # now have the reconstruction through the network\n",
    "    y = current_input\n",
    "    # y = reconstruction\n",
    "    # cost function measures pixel-wise difference\n",
    "    # cost = tf.reduce_sum(tf.square(y - target))\n",
    "    cost = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output))\n",
    "    \"\"\"\n",
    "    cost = -tf.reduce_sum(tf.reduce_sum(\n",
    "            y_tensor * tf.log(y + 1e-10) + \\\n",
    "            (1 - y_tensor) * tf.log(1 - y + 1e-10),\n",
    "            reduction_indices=[1]\n",
    "        ))\n",
    "    \"\"\"\n",
    "\n",
    "    # %%\n",
    "    return {'x': x, 'target': target, 'z': z, 'y': y, 'cost': cost}\n",
    "\n",
    "def debug():\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    ae = autoencoder()\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batch_xs, _ = mnist.train.next_batch(1)\n",
    "    sess.run(ae['cost'], feed_dict={ae['x']: batch_xs})\n",
    "\n",
    "# %%\n",
    "def test_mnist():\n",
    "    \"\"\"Test the convolutional autoencder using MNIST.\"\"\"\n",
    "\n",
    "    # %%\n",
    "    # load MNIST as before\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    mean_img = np.mean(mnist.train.images, axis=0)\n",
    "    ae = autoencoder()\n",
    "\n",
    "    # %%\n",
    "    learning_rate = 0.01\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(ae['cost'])\n",
    "\n",
    "    # %%\n",
    "    # We create a session to use the graph\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # %%\n",
    "    # Fit all training data\n",
    "    batch_size = 100\n",
    "    n_epochs = 100\n",
    "    for epoch_i in range(n_epochs):\n",
    "        for batch_i in range(mnist.train.num_examples // batch_size):\n",
    "            batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "            train = np.array([img - mean_img for img in batch_xs])\n",
    "            sess.run(optimizer, feed_dict={ae['x']: batch_xs, ae['target']: batch_xs})\n",
    "        print(epoch_i, sess.run(ae['cost'], feed_dict={ae['x']: batch_xs, ae['target']: batch_xs}))\n",
    "\n",
    "    # %%\n",
    "    # Plot example reconstructions\n",
    "    n_examples = 10\n",
    "    test_xs, _ = mnist.test.next_batch(n_examples)\n",
    "    test_xs_norm = np.array([img - mean_img for img in test_xs])\n",
    "    recon = sess.run(ae['y'], feed_dict={ae['x']: test_xs, ae['target']: test_xs})\n",
    "    \n",
    "    #print(recon.shape)\n",
    "    fig, axs = plt.subplots(2, n_examples, figsize=(10, 2))\n",
    "    for example_i in range(n_examples):\n",
    "        error = ll(test_xs[example_i, :], np.reshape(recon[example_i, ...], (784,))) # + mean_img)\n",
    "        print(error)\n",
    "        \n",
    "        axs[0][example_i].imshow(\n",
    "            np.reshape(test_xs[example_i, :], (28, 28)))\n",
    "        axs[1][example_i].imshow(\n",
    "            np.reshape(\n",
    "                np.reshape(recon[example_i, ...], (784,)), # + mean_img,\n",
    "                (28, 28)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# %%\n",
    "if __name__ == '__main__':\n",
    "    test_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With additional FC and sigmoid: Total Loss: 5115, img reconstr error: 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without FC: Loss: 4900, large img reconstr error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: No sigmoid after deconv layer???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "171000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
