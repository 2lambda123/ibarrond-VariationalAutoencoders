Architecture: [784, 2048, 2048, 2048, 2, 2048, 2048, 2048, 784]

Variational Autoencoder:
-------------------------------------

W_enc1 = 784 x 2048 + 2048 = 1607680
W_enc2 = 2048 x 2048 + 2048 = 4196352
W_enc3 = 2048 x 2048 + 2048 = 4196352

W_mu = 2048 x 2 + 2 = 4098
b_log_sigma = 2048 x 2 + 2 = 4098

W_dec1 = 2 x 2048 + 2048 = 6144
W_dec2 = 2048 x 2048 + 2048 = 4196352
W_dec3 = 2048 x 2048 + 2048 = 4196352

W_mu_dec = 2048 x 784 + 784 = 1606416

-------------------------------------
SUM = 21,620,260




Bayesian DNN:
------------------------------------------

Priors Mus & Sigmas:

W_enc1 = 2x (784 x 2048 + 2048) = 3215360
W_enc2 = 2x (2048 x 2048 + 2048) = 8392704
W_enc3 = 2x (2048 x 2048 + 2048) = 8392704

W_mu = 2048 x 2 + 2 = 4098
b_log_sigma = 2048 x 2 + 2 = 4098

W_dec1 = 2x (2 x 2048 + 2048) = 12288
W_dec2 = 2x (2048 x 2048 + 2048) = 8392704
W_dec3 = 2x (2048 x 2048 + 2048) = 8392704

W_mu_dec = 2x (2048 x 784 + 784) = 3212832

------------------------------------------
SUM = 43,232,324

+ the same for the variational distribution
=  2x43,232,324
=> SUM = 86,464,648

=> Idea: Use a constant prior to halve parameters (KL-div towards std. normal)!